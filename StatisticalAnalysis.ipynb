{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hashlib import blake2b \n",
    "class MapResult():\n",
    "    \n",
    "    import pickle\n",
    "    import math\n",
    "    statistika = None\n",
    "    words1= None\n",
    "    words2 = None\n",
    "    emb1 = \"\"\n",
    "    emb2 = \"\"\n",
    "    vzdalenostniMapa = None\n",
    "    embeddingy = None\n",
    "    dtype = [(\"avg\",float),(\"index\",float),(\"nRecords\",float)]\n",
    "    words = None \n",
    "    \n",
    "    def __init__(self,emb1 = \"\", emb2 = \"\", words1 = None, words2=None,vzdalenostniMapa=None,text = \"\"):\n",
    "        self.emb1 = emb1\n",
    "        self.emb2 = emb2\n",
    "        self.words1 = words1\n",
    "        self.words2 = words2\n",
    "        self.vzdalenostniMapa = vzdalenostniMapa\n",
    "        if(text != \"\"):\n",
    "            self.words = text\n",
    "            embeddingy = Embeddings_ready(text=text)\n",
    "            #self.emb1 = embeddingy\n",
    "            #self.emb1 = #TODO - Hledání + načítání z disku podle názvu / hashe / db?... prostě něco\n",
    "            self.vzdalenostniMapa = embeddingy.generateMap()\n",
    "    \n",
    "    def toString(self):\n",
    "        return(\"words1: \" + str(self.words1 or \"None\") + \"\\n\" +\n",
    "              \"words2: \" + str(self.words2 or \"None\") + \"\\n\" +\n",
    "               \"emb1: \" + str(self.emb1) + \"\\n\"+\n",
    "               \"emb2: \" + str(self.emb2) + \"\\n\"+\n",
    "               \"statistika: \" + str(self.statistika or \"None\") + \"\\n\"+\n",
    "               \"vzdalenostniMapa: \" + str(self.vzdalenostniMapa or \"None\") + \"\\n\"              )\n",
    "        \n",
    "  \n",
    "    \n",
    " \n",
    "    def getHash(self, words:str = None):\n",
    "        hasher = blake2b()\n",
    "        if (self != None):\n",
    "            if(self.words == None):\n",
    "                words = self.words1+self.words2\n",
    "            else: \n",
    "                words=self.words\n",
    "            \n",
    "        hasher.update(bytes(words,\"UTF-8\"))\n",
    "        return hasher.hexdigest()\n",
    "    \n",
    "    def getEmbeddings(self,number:int = 0):\n",
    "        if(number == 0):\n",
    "            if(self.emb1==\"\"):\n",
    "                return None #Asi by měl Raisnout Exception\n",
    "            return pickle.load(open(self.emb1,\"rb\"))\n",
    "                \n",
    "        elif(number == 1):\n",
    "            if(self.emb2==\"\"):\n",
    "                if(self.emb1==\"\"):\n",
    "                    return None #Asi by měl Raisnout Exception\n",
    "                return pickle.load(open(self.emb1,\"rb\"))\n",
    "            return pickle.load(open(self.emb2,\"rb\")) \n",
    "            \n",
    "        return None #DEFAULT \n",
    "    \n",
    "    def getVzdalenostniMapa(self):\n",
    "        if(self.vzdalenostniMapa == None):\n",
    "            self.generateMap()\n",
    "        return self.vzdalenostniMapa\n",
    "    \n",
    "    def generateMap(self,matrix=None,firstSEC:int = 0, secondSEC:int = 1):\n",
    "        if(matrix == None):\n",
    "            \n",
    "            matrix = self.getEmbeddings().getMapReadyEmbeddings(anotherClass=self.getEmbeddings(number=1),\n",
    "                                                                firstSEC=firstSEC,\n",
    "                                                                secondSEC=secondSEC)\n",
    "        retVal = []\n",
    "        for i in range(np.size(matrix,0)):\n",
    "            retVal.append([])\n",
    "            for j in range(np.size(matrix,1)):\n",
    "                retVal[i].append(modelDist(matrix[i][j])[1][0][0].numpy()[0])\n",
    "        #print(modelDist(matrix[i][j])[1][0][0].numpy()[0])\n",
    "        self.vzdalenostniMapa= retVal\n",
    "    \n",
    "    \n",
    "    def Statistics(self, mapaData=None):\n",
    "        #TODO: Další statistické funkce, možná úprava ztrátové funkce, či něco dalšího\n",
    "        if(mapaData ==None):\n",
    "            mapaData = self.getVzdalenostniMapa()\n",
    "        nRecords = np.size(mapaData,0)-1\n",
    "        rangeMax = round(nRecords/2)\n",
    "        #best_avg = 0\n",
    "        #pos_avg = 0\n",
    "        mapaData2 = np.array(mapaData)\n",
    "        all_Avgs = []\n",
    "        for i in range(-rangeMax,rangeMax): \n",
    "            #Validation_bias - \"ztrátová funkce\" pro průměry mimo očekávanou osu\n",
    "            #validation_bias = 1-abs((i+30)/nRecords)\n",
    "            all_Avgs.append((np.average(mapaData2.diagonal(i)),i,rangeMax-i))\n",
    "        return all_Avgs\n",
    "    \n",
    "    def prumery(self,statistika):\n",
    "        np.flip(np.sort(np.array(statistika,dtype=self.dtype),order=\"avg\"))\n",
    "    \n",
    "    def pickleThis(self,path:str = \"./Pickles\"):\n",
    "        hash = self.getHash()\n",
    "        with open(path+\"/\"+hash+\".pickle\",\"wb\") as p:\n",
    "            pickle.dump(self,p)\n",
    "            p.close()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmapa(vstup1,vstup2,delimiter):\n",
    "    \n",
    "    \n",
    "    splittedString1 = textSplitter(vstup1,delimiter)\n",
    "    splittedString2 = textSplitter(vstup2,delimiter)\n",
    "    \n",
    "    \n",
    "    delka1 = len(splittedString1)                \n",
    "    delka2 = len(splittedString2)\n",
    "\n",
    "    \n",
    "    \n",
    "    mapa = np.zeros((delka1,delka2))\n",
    "    for i in range(delka1-1):\n",
    "    #X\n",
    "        for j in range(delka2-1):\n",
    "            #Y\n",
    "            #print(splittedString[i] + \" \" + splittedString[i+1]     )\n",
    "            batch = []\n",
    "            batch.append(((splittedString1[i],splittedString1[i+1],splittedString2[j],splittedString2[j+1]),0))\n",
    "            vectorized = vectorize_batch(batch,mask=False)        \n",
    "            out = model.predict(vectorized,batch_size = 32)\n",
    "            mapa[i,j+1] = out[\"out\"][0][3]\n",
    "            mapa[i+1,j] = out[\"out\"][0][2]\n",
    "    return mapa\n",
    "\n",
    "def textSplitter(vstup, condition):\n",
    "    #Musí být ve stejné velikosti jako výukové okno - 32\n",
    "    #NEW:\n",
    "    vstup += ' '*32\n",
    "    vstup.replace('\\n',\"\")\n",
    "    if(condition.isnumeric()):\n",
    "        cislo = int(condition)\n",
    "        if(len(vstup)<32):\n",
    "            #print(len(vstup))\n",
    "            return [vstup]        \n",
    "        return [vstup[i:i+32] for i in range(0,len(vstup)-32,cislo)]\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        return vstup.split(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn\n",
    "import matplotlib as mpl\n",
    "def Mapa(vstup,exportName:str = \"\",title:str = \"\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    viridis = mpl.colormaps['viridis'].resampled(256)\n",
    "    newcolors = viridis(np.linspace(0, 1, 256))\n",
    "    pink = np.array([248/256, 24/256, 148/256, 1])\n",
    "    black = np.array([0/256, 0/256, 0/256, 1])\n",
    "    newcolors[-16:, :] = pink\n",
    "    newcolors[:16,:] = black\n",
    "\n",
    "\n",
    "    ax = seaborn.heatmap(vstup,annot =False, cmap =  mpl.colors.ListedColormap(newcolors))\n",
    "    ax.set(xlabel=\"\", ylabel=\"\",title=title)\n",
    "    ax.xaxis.tick_top()\n",
    "    plt.xticks(rotation=90)\n",
    "    if(exportName != \"\"):\n",
    "        plt.savefig(exportName,bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    #TODO: SaveFig\n",
    "    #plt.savefig(\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "class Embeddings_ready():\n",
    "    \n",
    "    arr_embeddings = []\n",
    "    strings = []\n",
    "    \n",
    "    def __init__(self, path:str = \"\",embeddings= [],text:str =\"\"):\n",
    "        if(path != \"\"):\n",
    "            self.loadPickle(path)\n",
    "        elif(text != \"\"):\n",
    "            self.arr_embeddings = self.prepEmbeddings(text)\n",
    "\n",
    "        elif(len(embeddings)>0):\n",
    "            self.arr_embeddings = embeddings\n",
    "            \n",
    "        \n",
    "    def loadPickle(self,path:str):\n",
    "        with open(path,\"rb\") as p:\n",
    "            self.arr_embeddings= pickle.load(p)\n",
    "        \n",
    "    def savePickle(self, path:str):\n",
    "        with open(path,\"wb\") as p:\n",
    "            return pickle.dump(self.arr_embeddings,p)\n",
    "        \n",
    "    def getEmbeddings(self):\n",
    "        return self.arr_embeddings\n",
    "    \n",
    "    #firstSEC, secondSEC - označuje zda používáme z embeddings \"pos1\" nebo \"pos2\" sloupec - 0 = pos1, 1 = pos2\n",
    "    def getMapReadyEmbeddings(self, anotherClass = None,firstSEC:int = 1, secondSEC:int = 0):\n",
    "        retVal = []\n",
    "        if(anotherClass == None):\n",
    "            anotherClass = self\n",
    "        \n",
    "       \n",
    "        for i in range(len(self.arr_embeddings[0])):\n",
    "            retVal.append([])\n",
    "            #print(len(retVal))\n",
    "            for j in range(len(anotherClass.arr_embeddings[0])):\n",
    "                retVal[i].append([self.arr_embeddings[firstSEC][i:i+1],anotherClass.arr_embeddings[secondSEC][j:j+1]])\n",
    "                #retVal[i].\n",
    "                next\n",
    "        return retVal\n",
    "                \n",
    "    def prepEmbeddings(self,text:str,n_Chars:int = 1):\n",
    "        \n",
    "        splitted = textSplitter(text,str(n_Chars))\n",
    "        self.strings = splitted\n",
    "\n",
    "        embedded = vlastni_vectorize_batch(splitted)\n",
    "        return embedded\n",
    "    \n",
    "    \n",
    "    def generateMap(self,matrix=None,firstSEC:int = 1, secondSEC:int = 0):\n",
    "        if(matrix == None):\n",
    "            matrix = self.getMapReadyEmbeddings(firstSEC=firstSEC, secondSEC=secondSEC)\n",
    "        retVal = []\n",
    "        for i in range(np.size(matrix,0)):\n",
    "            retVal.append([])\n",
    "            for j in range(np.size(matrix,1)):\n",
    "                retVal[i].append(modelDist(matrix[i][j])[1][0][0].numpy()[0])\n",
    "        #print(modelDist(matrix[i][j])[1][0][0].numpy()[0])\n",
    "        return retVal\n",
    "        \n",
    "        \n",
    "        #Asi zatím nemá smysl, aby existoval:\n",
    "    def getWords(self,number:int = 0):\n",
    "        if(number == 0):\n",
    "            if(self.words1==None):\n",
    "                return None #Asi by měl Rasinout exception?\n",
    "            return self.words1\n",
    "\n",
    "\n",
    "        elif(number == 1):\n",
    "            if(self.words2 == None):\n",
    "                if(self.words1 == None):\n",
    "                    return None #Asi by měl Rasinout exception?\n",
    "                return self.words1\n",
    "            return self.words2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = \"./Pickles/Words/\"\n",
    "overwrite = False\n",
    "\n",
    "\n",
    "for i in os.listdir(directory):\n",
    "    if(not i.endswith(\".pickle\")):\n",
    "        print(i)\n",
    "        continue\n",
    "    f = os.path.join(directory,i)\n",
    "    print(f)\n",
    "    if(os.path.isfile(f)):\n",
    "        try:\n",
    "            if((not os.path.isfile(f.replace(\".pickle\",\".png\"))) or overwrite):\n",
    "                s = pickle.load(open(f,'rb'))\n",
    "                slova = textSplitter(s.words.replace('\\n',''),str(1))\n",
    "                Mapa(pd.DataFrame(data = s.vzdalenostniMapa,\n",
    "                            index =  slova,\n",
    "                            columns =  slova\n",
    "                            ),f.replace(\".pickle\",\".png\"),s.words)\n",
    "                            #f.replace(\".pickle\",\".png\")\n",
    "             \n",
    "        except Exception as e:\n",
    "            print(\"wtf2 : \" + str(e) )\n",
    "            continue\n",
    "    else:\n",
    "        print(\"wtf\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = pickle.load(open(\"./Pickles/old/868843c76aea94b09d28fa6d64b0292e8b638c20f90e90deee7b382619679aab1d6a19ece5cac33f5460196c15a7a5a48c60c189520b24b8d21d9faadec4ef3a.pickle\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Následující funkce počítá průměrné hodnoty jednotlivých diagonál dle relativní odchylky od hlavní diagonály."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from statistics import mean\n",
    "directory = \"./Pickles/ProteinCLS/\"\n",
    "overwrite = False\n",
    "\n",
    "maxDelka = 0 \n",
    "slovnikOffsetuMatice = []\n",
    "fileCounter = 0\n",
    "for i in os.listdir(directory):\n",
    "    if(not i.endswith(\".pickle\")):\n",
    "        #print(i)\n",
    "        continue\n",
    "    f = os.path.join(directory,i)\n",
    "    #print(f)\n",
    "\n",
    "    if(os.path.isfile(f)):\n",
    "        try:\n",
    "            s = pickle.load(open(f,'rb'))\n",
    "            vstupniText = s.words\n",
    "            #print(vstupniText)\n",
    "            \n",
    "\n",
    "            \n",
    "            #print(s.vzdalenostniMapa())\n",
    "            matice = np.array(s.getVzdalenostniMapa())\n",
    "            delka = np.size(matice, 0)\n",
    "            maxDelka = max(maxDelka,delka)\n",
    "            for offst in range(-delka+1, delka-1):\n",
    "                slovnikOffsetuMatice.append([offst,matice.diagonal(offst).sum()/delka , fileCounter])\n",
    "                #print(matice.diagonal(offst).sum() / delka)\n",
    "            #print(slovnikOffsetuMatice)\n",
    "            fileCounter+=1\n",
    "\n",
    "            \n",
    "            #print(matice)\n",
    "            #break\n",
    "\n",
    "            #num_rows, num_cols = matice.shape()\n",
    "\n",
    "            #print(matice.diagonal(num_rows))\n",
    "            #print(\"..\")\n",
    "            \n",
    "\n",
    "             \n",
    "        except Exception as e:\n",
    "            print(\"wtf2 : \" + str(e) )\n",
    "            continue\n",
    "    else:\n",
    "        print(\"wtf\")\n",
    "\n",
    "\n",
    "sortedArray = sorted(slovnikOffsetuMatice, key=lambda x: x[1],reverse= True)\n",
    "\n",
    "#print(sortedArray[0])\n",
    "minimalVal  = np.min(sortedArray,).astype(int)\n",
    "maxVal = np.max(sortedArray,).astype(int)\n",
    "\n",
    "arr_sum = np.zeros(maxVal-minimalVal+2,).tolist()\n",
    "arr_count = np.zeros(maxVal-minimalVal+2,).tolist()\n",
    "\n",
    "\n",
    "for i in sortedArray:\n",
    "    #print(i[1])\n",
    "    arr_sum[-minimalVal+i[0]] += i[1]\n",
    "    arr_count[-minimalVal+i[0]] += 1\n",
    "\n",
    "\n",
    "#print(arr_sum)\n",
    "prumery = []\n",
    "\n",
    "for i in range(0,len(arr_sum)):\n",
    "    #print(i)\n",
    "    if(arr_count[i] == 0):\n",
    "        #print(arr_sum[i],arr_count[i])\n",
    "        continue\n",
    "    prumery.append([i+minimalVal , arr_sum[i] /  arr_count[i]])\n",
    "\n",
    "prumerySerazeno =sorted(prumery, key=lambda x: x[1],reverse= True)\n",
    "\n",
    "\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export výsledků do formátu jednoduše zobrazitelného matlabem\n",
    "kekw = np.array(sorted(prumery, key=lambda x: x[0]))\n",
    "l = np.transpose(kekw).tolist()\n",
    "print(\"x = \" ,l[0],\";\")\n",
    "print(\"y = \" ,l[1],\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOHLE JE ŠÍLENSTVÍ - EXTRÉMNĚ MNOHO DAT!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from statistics import mean\n",
    "from collections import Counter\n",
    "\n",
    "directory = \"./Pickles/Words/\"\n",
    "overwrite = False\n",
    "\n",
    "serazeniPpsti = None\n",
    "\n",
    "maxDelka = 0 \n",
    "slovnikOffsetuMatice = []\n",
    "\n",
    "#counts [i] = counts.get(i, 0) + 1\n",
    "slovnikPoctu = dict()\n",
    "slovnikPpsti = dict()\n",
    "\n",
    "fileCounter = 0\n",
    "for i in os.listdir(directory):\n",
    "    if(not i.endswith(\".pickle\")):\n",
    "        #print(i)\n",
    "        continue\n",
    "    f = os.path.join(directory,i)\n",
    "    #print(f)\n",
    "\n",
    "    if(os.path.isfile(f)):\n",
    "        try:\n",
    "            s = pickle.load(open(f,'rb'))\n",
    "            vstupniText = s.words\n",
    "            #print(vstupniText)\n",
    "            \n",
    "\n",
    "            \n",
    "            #print(s.vzdalenostniMapa())\n",
    "            matice = np.array(s.getVzdalenostniMapa())\n",
    "            delka = np.size(matice, 0)            \n",
    "\n",
    "            #Projdi všechny výsledky matice\n",
    "            \n",
    "            for g in range(0,delka): #Vertical\n",
    "                for h in range(0,delka): #Horizontal\n",
    "                    #Každou hodnotu přičti do slovníků všech možných proměnných\n",
    "                    for j in range(1,6):\n",
    "                        subString = vstupniText[g+30-j:g+30]+vstupniText[h:h+j]\n",
    "                        #print(subString)\n",
    "                        #print(vstupniText)\n",
    "                        slovnikPoctu[subString] = slovnikPoctu.get(subString,0)+1\n",
    "                        slovnikPpsti[subString] = slovnikPoctu.get(subString,0)+matice[g,h]\n",
    "\n",
    "                        #print(slovnikPoctu)\n",
    "                        #print(slovnikPpsti)\n",
    "                        #return\n",
    "            print(\".\",end=\"\")           \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #print(matice.diagonal(offst).sum() / delka)\n",
    "            #print(slovnikOffsetuMatice)\n",
    "            fileCounter+=1\n",
    "\n",
    "            \n",
    "            #print(matice)\n",
    "            #break\n",
    "\n",
    "            #num_rows, num_cols = matice.shape()\n",
    "\n",
    "            #print(matice.diagonal(num_rows))\n",
    "            #print(\"..\")\n",
    "            \n",
    "\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"wtf2 : \" + str(e) )\n",
    "            continue\n",
    "    else:\n",
    "        print(\"wtf\")\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74918865\n"
     ]
    }
   ],
   "source": [
    "print(len(slovnikPoctu))\n",
    "slovnikPrumerPpsti = dict()\n",
    "pocetSpojeni = sum(slovnikPoctu.values())\n",
    "\n",
    "for i in slovnikPpsti.keys():\n",
    "    slovnikPrumerPpsti[i] = slovnikPpsti[i] / pocetSpojeni\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slovnikPpsti = None\n",
    "slovnikPoctu = None\n",
    "serazeniPpsti = sorted(slovnikPrumerPpsti.items(), key = lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "serazeniPpsti = sorted(slovnikPrumerPpsti.items(), key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' o', 0.0019429110337580004)\n"
     ]
    }
   ],
   "source": [
    "print(serazeniPpsti[3\n",
    "                    \n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "soucet = 0\n",
    "soucet2 = 0\n",
    "pocet = 0\n",
    "pocet2 = 0\n",
    "for i in serazeniPpsti:\n",
    "    if(\" \" in i[0][int(len(i[0])/2) : int(len(i[0])/2)+1 ]):\n",
    "        soucet += i[1]\n",
    "        pocet+=1\n",
    "    else:\n",
    "        soucet2 += i[1]\n",
    "        pocet2+= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1745078081468546\n",
      "1.017596839827804\n",
      "9364668\n",
      "65554197\n"
     ]
    }
   ],
   "source": [
    "print(soucet)\n",
    "print(soucet2)\n",
    "print(pocet)\n",
    "print(pocet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Souvislost na hranici slov =1.863470313596324e-08\n",
      "Souvislost uprostřed slov =1.5522985352529052e-08\n"
     ]
    }
   ],
   "source": [
    "print(\"Souvislost na hranici slov =\" + str(soucet/pocet))\n",
    "print(\"Souvislost uprostřed slov =\" + str(soucet2/pocet2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dict()\n",
    "for i in items:\n",
    "  counts[i] = counts.get(i, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(np.zeros((3,)).tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kekw2 = np.zeros((2,2))\n",
    "print(kekw2.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(arr_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(s.words)##\n",
    "# #print(textSplitter(s.words.replace('\\n',' '),str(1)))\n",
    "# print(s.toString())\n",
    "# slova = textSplitter(s.words,str(1))\n",
    "\n",
    "# Mapa(pd.DataFrame(data = s.vzdalenostniMapa,\n",
    "#                            index =  slova,\n",
    "#                            columns =  slova\n",
    "#                           ),\"./Pickles/old/868843c76aea94b09d28fa6d64b0292e8b638c20f90e90deee7b382619679aab1d6a19ece5cac33f5460196c15a7a5a48c60c189520b24b8d21d9faadec4ef3a.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vysledky = []\n",
    "#with open(\"./CC-aug2018-oct2021_ces.10G_val.tsv\",\"r\",encoding = \"utf8\") as reader:\n",
    "   #uniref90_tax-free_shuffled_val.tsv\n",
    "\n",
    "soubory = {\"./uniref90_tax-free_shuffled_val.tsv\",\"./uniref90_tax-free_shuffled_train.tsv\" }\n",
    "\n",
    "soubory = {\"./CC-aug2018-oct2021_ces.10G_train.tsv\",\"./CC-aug2018-oct2021_ces.10G_val.tsv\"}\n",
    "meziVysledky = []\n",
    "megas = 0\n",
    "counter = 0 \n",
    "for x in soubory:\n",
    "   with open(x,\"r\",encoding = \"utf8\") as reader:\n",
    "      for i in reader:\n",
    "         length = len(i.split(\"\\t\")[-1])\n",
    "         if(length == 1):\n",
    "            continue\n",
    "         meziVysledky.append(length)\n",
    "         counter += 1\n",
    "         if(counter % 1_000_000 == 0):\n",
    "            print(\".\",end=\"\")\n",
    "            numpyVysledky = np.array(meziVysledky)\n",
    "            megas+=1\n",
    "            vysledky.append([megas,np.median(numpyVysledky),np.max(numpyVysledky), np.min(numpyVysledky), np.average(numpyVysledky), np.sum(numpyVysledky)])\n",
    "            meziVysledky = []\n",
    "      reader.close()\n",
    "   print(\"\\n-----\\n\")\n",
    "\n",
    "numpyVysledky = np.array(meziVysledky)\n",
    "megas+=(counter%1_000_000)/1_000_000\n",
    "vysledky.append([megas,np.median(numpyVysledky),np.max(numpyVysledky), np.min(numpyVysledky), np.average(numpyVysledky), np.sum(numpyVysledky)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpyVysledky = np.array(vysledky)\n",
    "print(\"celkem:\", counter)\n",
    "print(np.median(numpyVysledky),np.max(numpyVysledky), np.min(numpyVysledky), np.average(numpyVysledky), np.sum(numpyVysledky))\n",
    "\n",
    "vysledky[-1][0] -= 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vysledky[-1][0] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in vysledky:\n",
    "#   print(i)\n",
    "\n",
    "print(np.max(vysledky[:][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vysl = np.array(vysledky)\n",
    "#print(vysl[:,0])\n",
    "\n",
    "print(\"median = \",np.median(vysl[:,1]), \"max = \",np.max(vysl[:,2]),\"; min = \", np.min(vysl[:,3]) , \"; avg = \",  np.average(vysl[:,4]) ,\"; sum = \", np.sum(vysl[:,5])   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in vysl:\n",
    "    if(i[2 ] == 45355 ):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meziVysledky = []\n",
    "megas = 0\n",
    "counter = 0 \n",
    "for x in soubory:\n",
    "   with open(x,\"r\",encoding = \"utf8\") as reader:\n",
    "      for i in reader:\n",
    "         if(len(i.split(\"\\t\")[-1])== 1):\n",
    "           print(\"wtf?!\" + i)\n",
    "           break\n",
    "      reader.close()\n",
    "   print(\"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vysl[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soubory = {\"./CC-aug2018-oct2021_ces.10G_train.tsv\",\"./CC-aug2018-oct2021_ces.10G_val.tsv\"}\n",
    "import re\n",
    "\n",
    "pattern = re.compile(r\"[äöüßÄÖÜẞ]+\",re.IGNORECASE)\n",
    "\n",
    "pismenka = {'ü','ö','ä','ß',''}\n",
    "for x in soubory:\n",
    "   with open(x,\"r\",encoding = \"utf8\") as reader:\n",
    "      for i in reader:\n",
    "         if(pattern.search(i)):\n",
    "           print(\"wtf?!\" + i)\n",
    "           \n",
    "      reader.close()\n",
    "   print(\"\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = \"./Pickles/Words/\"\n",
    "overwrite = False\n",
    "\n",
    "\n",
    "for i in os.listdir(directory):\n",
    "    if(not i.endswith(\".pickle\")):\n",
    "        print(i)\n",
    "        continue\n",
    "    f = os.path.join(directory,i)\n",
    "    print(f)\n",
    "    if(os.path.isfile(f)):\n",
    "        try:\n",
    "            if((not os.path.isfile(f.replace(\".pickle\",\".png\"))) or overwrite):\n",
    "                s = pickle.load(open(f,'rb'))\n",
    "                slova = textSplitter(s.words.replace('\\n',''),str(1))\n",
    "                Mapa(pd.DataFrame(data = s.vzdalenostniMapa,\n",
    "                            index =  slova,\n",
    "                            columns =  slova\n",
    "                            ),f.replace(\".pickle\",\".png\"),s.words)\n",
    "                            #f.replace(\".pickle\",\".png\")\n",
    "             \n",
    "        except Exception as e:\n",
    "            print(\"wtf2 : \" + str(e) )\n",
    "            continue\n",
    "    else:\n",
    "        print(\"wtf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
